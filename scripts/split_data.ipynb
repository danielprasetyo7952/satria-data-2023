{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This code is a data preprocessing script that is used for creating a dataset to train, validate and test an image classification model. Specifically, it creates a dataset of fruit images, including Apples, Bananas, Grapes, Mangos, and Strawberries.\n",
    "\n",
    "The script first defines the class names and number of images per class by counting the number of files in the directory for each fruit. It then creates three directories, one for each dataset split, i.e., training, validation, and testing. These directories are created if they don't exist.\n",
    "\n",
    "The script then creates subdirectories in each of the three main directories for each fruit class. This step creates a hierarchical structure for the dataset, where each fruit class has a folder in each dataset split directory.\n",
    "\n",
    "Next, the script collects all the image paths for each fruit class, storing them in a list. It then shuffles the paths randomly to ensure that the data is not biased in any way.\n",
    "\n",
    "The script then calculates the size of each dataset split based on the total number of images and predefined ratios. The training dataset is the largest, comprising 97% of the total data, while the validation and testing datasets comprise 2% and 1%, respectively.\n",
    "\n",
    "The script then creates three separate lists, one for each dataset split, containing tuples with the old and new paths for each image. The new paths are generated by concatenating the class folder, the image filename, and the corresponding dataset split directory.\n",
    "\n",
    "Finally, the script moves each image from its old path to its new path in the appropriate dataset split directory using the os.rename() function. It then removes the old directories for each fruit class, as they are no longer needed.\n",
    "\n",
    "The script outputs the total size of the data, as well as the size of each dataset split. Once the script finishes running, the dataset is ready to use for training, validating, and testing an image classification model.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define class names and number of images per class\n",
    "class_names = os.listdir(\"../balanced-data-split/\")\n",
    "n_images_per_class = len(os.listdir(f\"./{class_names[0]}\"))\n",
    "\n",
    "# Define train, valid, and test directories and create them if they don't exist\n",
    "train_dir = \"./train\"\n",
    "valid_dir = \"./valid\"\n",
    "test_dir  = \"./test\"\n",
    "\n",
    "for directory in [train_dir, valid_dir, test_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Create subdirectories for each class in train, valid, and test directories\n",
    "for name in class_names:\n",
    "    for directory in [train_dir, valid_dir, test_dir]:\n",
    "        class_path = os.path.join(directory, name)\n",
    "        if not os.path.exists(class_path):\n",
    "            os.makedirs(class_path)\n",
    "\n",
    "# Collect all image paths for each class\n",
    "all_class_paths = [glob(f\"./{name}/*\") for name in class_names]\n",
    "\n",
    "# Define training, validation, and testing size\n",
    "total_size = sum([len(paths) for paths in all_class_paths])\n",
    "\n",
    "train_ratio = 0.80\n",
    "valid_ratio = 0.10\n",
    "test_ratio  = 0.10\n",
    "\n",
    "train_size = int(total_size * train_ratio)\n",
    "valid_size = int(total_size * valid_ratio)\n",
    "test_size  = int(total_size * test_ratio)\n",
    "\n",
    "train_images_per_class = int(n_images_per_class * train_ratio)\n",
    "valid_images_per_class = int(n_images_per_class * valid_ratio)\n",
    "test_images_per_class  = int(n_images_per_class * test_ratio)\n",
    "\n",
    "print(\"Total Data Size  :   {}\".format(total_size))\n",
    "print(\"Training Size    :   {}\".format(train_size))\n",
    "print(\"Validation Size  :   {}\".format(valid_size))\n",
    "print(\"Testing Size     :   {}\\n\".format(test_size))\n",
    "\n",
    "# Shuffle image paths for each class\n",
    "for paths in all_class_paths:\n",
    "    np.random.shuffle(paths)\n",
    "\n",
    "# Define lists of (old_path, new_path) tuples for training, validation, and testing images\n",
    "train_images = [(path, os.path.join(train_dir, path.split('/')[-2], path.split('/')[-1])) for paths in all_class_paths for path in paths[:train_images_per_class]]\n",
    "valid_images = [(path, os.path.join(valid_dir, path.split('/')[-2], path.split('/')[-1])) for paths in all_class_paths for path in paths[train_images_per_class: train_images_per_class + valid_images_per_class]]\n",
    "test_images  = [(path, os.path.join(test_dir, path.split('/')[-2], path.split('/')[-1]))  for paths in all_class_paths for path in paths[train_images_per_class+valid_images_per_class: train_images_per_class + valid_images_per_class + test_images_per_class]]\n",
    "\n",
    "# Move images to their new directories\n",
    "for images, data_type in [(train_images, \"Training\"), (valid_images, \"Validation\"), (test_images, \"Testing\")]:\n",
    "    for (old_path, new_path) in tqdm(images, desc=data_type + \" Data\"):\n",
    "        os.rename(old_path, new_path)\n",
    "\n",
    "# Remove the old directories\n",
    "for directory in class_names:\n",
    "    shutil.rmtree('./', directory)\n",
    "    # os.rmdir(\"./\" + directory,) error if it stil contains data\n",
    "\n",
    "# Print confirmation message\n",
    "print(\"ALL DONE!!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
