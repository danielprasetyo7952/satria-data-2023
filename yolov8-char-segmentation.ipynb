{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### This notebook is created on Colab, you need to adjust the dataset to run it.\n",
        "\n",
        "author: [@caesariodito](https://github.com/caesariodito)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T11:07:05.273353Z",
          "iopub.status.busy": "2023-07-06T11:07:05.272973Z",
          "iopub.status.idle": "2023-07-06T11:07:05.278584Z",
          "shell.execute_reply": "2023-07-06T11:07:05.277460Z",
          "shell.execute_reply.started": "2023-07-06T11:07:05.273315Z"
        },
        "id": "bBjQZQW943C3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output as cls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-07-06T11:07:05.282582Z",
          "iopub.status.busy": "2023-07-06T11:07:05.281862Z"
        },
        "id": "iFg3dWMT43C4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%pip install ultralytics\n",
        "%pip install roboflow\n",
        "\n",
        "cls()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzlYhQkw43C5",
        "outputId": "e6cda52c-bfbe-4958-829c-8f7744b49fa9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.128 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 24.2/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTbgUkKl43C5"
      },
      "source": [
        "## YOLOv8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTI28dY843C7",
        "outputId": "a2b45132-015a-4de4-d979-074e21330be1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics<=8.0.20 is required but found version=8.0.128, to fix: `pip install ultralytics<=8.0.20`\n",
            "Downloading Dataset Version Zip in test3--2 to yolov8: 100% [43511194 / 43511194] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to test3--2 in yolov8:: 100%|██████████| 10662/10662 [00:00<00:00, 11146.44it/s]\n"
          ]
        }
      ],
      "source": [
        "# prepare the dataset here\n",
        "\n",
        "# in my case, I use roboflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oz3YL2k543C7"
      },
      "source": [
        "### Run on terminal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH1p53pw43C7",
        "outputId": "72228d6a-f754-494b-8114-fc214d1d733b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to yolov8s.pt...\n",
            "100% 21.5M/21.5M [00:00<00:00, 277MB/s]\n",
            "Ultralytics YOLOv8.0.128 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/test3--2/data.yaml, epochs=35, patience=50, batch=16, imgsz=(240, 80), save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 105MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11135987 parameters, 11135971 gradients\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
            "100% 6.23M/6.23M [00:00<00:00, 301MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ updating to 'imgsz=240'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
            "WARNING ⚠️ imgsz=[240] must be multiple of max stride 32, updating to [256]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/test3--2/train/labels... 5259 images, 459 backgrounds, 0 corrupt: 100% 5259/5259 [00:02<00:00, 1904.60it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain335_png_jpg.rf.3bf8e731e4273fe9fd840656f4b2df79.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain335_png_jpg.rf.6db25443c5a6003cd791df920adb059a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain335_png_jpg.rf.78aa55586faeb941bd3f640e9c1484f7.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain335_png_jpg.rf.a2193e4ba6f97e1112656cd9301b3574.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain335_png_jpg.rf.a7ce319f3b9fa0968fc8e89d9c16dd49.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain335_png_jpg.rf.c7a4313d642a21069c6fc2c1fa5a4fa7.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain335_png_jpg.rf.d2bf2aa6c696fdd428c42068264a199e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain335_png_jpg.rf.e66a4a706a1623827ddf3d121e84a56d.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain335_png_jpg.rf.e71d3d3882af418fe6cc7c60cebbfedb.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain35_png_jpg.rf.2fe8af4ff2494da90c6ae81816073b02.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain35_png_jpg.rf.4683df8932dd1ac59fdf7a683df17205.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain35_png_jpg.rf.4e1b17ca737352b8b912041de1024d09.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain35_png_jpg.rf.732e4118ed4bffc084ce3ff30959aa4a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain35_png_jpg.rf.7f2c78a104465fa141713de9a05b2098.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain35_png_jpg.rf.9820130e03e57bcc8db85d576831c130.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain35_png_jpg.rf.c978894791ea1c3427713f2df26ca305.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain35_png_jpg.rf.d5cf80be0a8e9018200f8ffb38669b0e.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain35_png_jpg.rf.e3611f025430707c21cf68f0eb5afe68.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain774_png_jpg.rf.46afbf11de4d53d9541741dc11eb9514.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain774_png_jpg.rf.b622e3e176710dcf4fca23fd1f82b6b6.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain774_png_jpg.rf.bc84736afc1be3d223805095027aeb89.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain774_png_jpg.rf.c7f2e3ace05a0616f569ea6ccbb23bac.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain774_png_jpg.rf.d3b802e37e48019df486f999a86f8574.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain774_png_jpg.rf.f782cb40f6f1793bbab541c95b4a7a19.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain92_png_jpg.rf.0fa873e571d45417f2b096e697fc61bf.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain92_png_jpg.rf.220f5c7b83ceff6dcbc0a528232033d4.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain92_png_jpg.rf.36d7da0563e174a66de6add3fa4813ac.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain92_png_jpg.rf.403284512233db26496b3d47217dd4e5.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain92_png_jpg.rf.60375cfd90e970f23127da2cf9a58529.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain92_png_jpg.rf.7833a227d5042e02f4e6040a96040bcf.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain92_png_jpg.rf.8e60f54b9540821cef619d986296cc67.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain92_png_jpg.rf.db3180732dd9f5eb264e45fec0b03b4a.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain92_png_jpg.rf.e691347c398195e7b636a19b7cd120e1.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain94_png_jpg.rf.10f672bbbf2aa1af88a0104cc0394627.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain94_png_jpg.rf.3344b62bfb8d3b1cb8951730574960cd.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain94_png_jpg.rf.3437908067973d183cf6ed90ebddada1.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain94_png_jpg.rf.67c5ceee376aa33f2c20d725b4f3da65.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain94_png_jpg.rf.82181627c2716fc046683a5bb6f11077.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain94_png_jpg.rf.98f314452c618aeba8df90038c0a89c1.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain94_png_jpg.rf.a6db6477700c8de794ae693954424fc7.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain94_png_jpg.rf.e6b0b11541a2112e0dbc14d91c6467f0.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /content/test3--2/train/images/DataTrain94_png_jpg.rf.f7c746a525e1e2906145d98a0a83e976.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/test3--2/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 25928, len(boxes) = 34361. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/test3--2/valid/labels... 32 images, 1 backgrounds, 0 corrupt: 100% 32/32 [00:00<00:00, 389.70it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/test3--2/valid/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 179, len(boxes) = 225. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 256 train, 256 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 35 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/35      1.01G      1.504      1.031       1.03        146        256: 100% 329/329 [01:07<00:00,  4.90it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.35s/it]\n",
            "                   all         32        225      0.882      0.956      0.929       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/35      1.08G      1.373     0.8538     0.9852        126        256: 100% 329/329 [00:57<00:00,  5.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.25it/s]\n",
            "                   all         32        225      0.919      0.956      0.921      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/35      1.09G      1.358     0.8475     0.9779        141        256: 100% 329/329 [00:57<00:00,  5.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.85it/s]\n",
            "                   all         32        225      0.889      0.958      0.942      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/35      1.08G      1.311     0.8193     0.9712        147        256: 100% 329/329 [00:56<00:00,  5.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.33it/s]\n",
            "                   all         32        225      0.882      0.934      0.927      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/35      1.09G      1.287     0.8055     0.9614        154        256: 100% 329/329 [00:56<00:00,  5.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.40it/s]\n",
            "                   all         32        225      0.888      0.954      0.941      0.666\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/35      1.08G      1.268     0.7929     0.9572        150        256: 100% 329/329 [00:56<00:00,  5.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.87it/s]\n",
            "                   all         32        225      0.893       0.96      0.951      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/35      1.08G      1.241     0.7796      0.947        139        256: 100% 329/329 [00:57<00:00,  5.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.19it/s]\n",
            "                   all         32        225      0.889      0.957      0.943      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/35      1.08G       1.23     0.7669     0.9462        143        256: 100% 329/329 [00:56<00:00,  5.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.59it/s]\n",
            "                   all         32        225       0.91      0.947       0.93      0.686\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/35      1.09G      1.224     0.7623     0.9469        146        256: 100% 329/329 [00:56<00:00,  5.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.31it/s]\n",
            "                   all         32        225      0.874      0.964      0.935      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/35      1.08G      1.201     0.7548     0.9424        177        256: 100% 329/329 [00:55<00:00,  5.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.86it/s]\n",
            "                   all         32        225      0.883      0.973      0.937       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/35      1.08G      1.188     0.7372     0.9384        163        256: 100% 329/329 [00:57<00:00,  5.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.98it/s]\n",
            "                   all         32        225       0.89      0.967      0.939      0.673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/35      1.07G      1.186      0.732      0.937        168        256: 100% 329/329 [00:56<00:00,  5.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.83it/s]\n",
            "                   all         32        225      0.888      0.955      0.929      0.658\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/35      1.08G      1.169     0.7211     0.9349        168        256: 100% 329/329 [00:56<00:00,  5.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.01it/s]\n",
            "                   all         32        225      0.872      0.969      0.929      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/35      1.08G      1.156     0.7174     0.9301        158        256: 100% 329/329 [00:56<00:00,  5.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.99it/s]\n",
            "                   all         32        225       0.89      0.973      0.927      0.657\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/35     0.956G      1.148     0.7006     0.9278        138        256: 100% 329/329 [00:58<00:00,  5.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.95it/s]\n",
            "                   all         32        225      0.892      0.952      0.922      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/35      1.08G      1.135      0.702     0.9258        119        256: 100% 329/329 [00:56<00:00,  5.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.56it/s]\n",
            "                   all         32        225      0.905      0.974      0.945      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/35     0.952G      1.136     0.6951     0.9287        131        256: 100% 329/329 [00:56<00:00,  5.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.40it/s]\n",
            "                   all         32        225      0.924      0.956      0.947      0.671\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/35      1.09G      1.128     0.6851     0.9218        109        256: 100% 329/329 [00:56<00:00,  5.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.63it/s]\n",
            "                   all         32        225      0.904      0.959      0.943      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/35      1.07G      1.131     0.6881     0.9236        151        256: 100% 329/329 [00:57<00:00,  5.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.51it/s]\n",
            "                   all         32        225      0.882      0.963      0.949      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/35      1.09G      1.107     0.6677       0.92        112        256: 100% 329/329 [00:56<00:00,  5.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.76it/s]\n",
            "                   all         32        225      0.889      0.973      0.941      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/35      1.08G      1.092     0.6639     0.9174        176        256: 100% 329/329 [00:56<00:00,  5.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.07it/s]\n",
            "                   all         32        225      0.887      0.978      0.946      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/35      1.07G      1.091     0.6603     0.9157        129        256: 100% 329/329 [00:58<00:00,  5.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.49it/s]\n",
            "                   all         32        225      0.883      0.956      0.925      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/35      1.09G      1.086     0.6533     0.9138        118        256: 100% 329/329 [00:56<00:00,  5.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.96it/s]\n",
            "                   all         32        225      0.894      0.942      0.916       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/35      1.08G       1.07     0.6416     0.9123        133        256: 100% 329/329 [00:56<00:00,  5.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.63it/s]\n",
            "                   all         32        225      0.885      0.969      0.931      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/35     0.956G       1.05     0.6333     0.9065        168        256: 100% 329/329 [00:56<00:00,  5.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  1.89it/s]\n",
            "                   all         32        225      0.903      0.955      0.939      0.643\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/35      1.07G      1.024     0.6256     0.9133         71        256: 100% 329/329 [00:44<00:00,  7.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.83it/s]\n",
            "                   all         32        225      0.907      0.952      0.936      0.659\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/35      1.09G      1.006      0.608     0.9087         67        256: 100% 329/329 [00:41<00:00,  7.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.02it/s]\n",
            "                   all         32        225      0.901      0.978      0.929      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/35      1.08G     0.9955     0.5873     0.9042         63        256: 100% 329/329 [00:42<00:00,  7.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.47it/s]\n",
            "                   all         32        225      0.912      0.956       0.93      0.665\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/35      1.07G     0.9718     0.5836     0.8989         65        256: 100% 329/329 [00:41<00:00,  7.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.00it/s]\n",
            "                   all         32        225      0.886       0.97      0.931      0.678\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/35      1.08G     0.9579     0.5655     0.8967         65        256: 100% 329/329 [00:42<00:00,  7.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  2.85it/s]\n",
            "                   all         32        225      0.907      0.953      0.915       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/35      1.07G      0.932     0.5462     0.8909         64        256: 100% 329/329 [00:41<00:00,  7.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.25it/s]\n",
            "                   all         32        225      0.915      0.963      0.947      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/35      1.07G     0.9265     0.5378     0.8903         63        256: 100% 329/329 [00:41<00:00,  7.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.59it/s]\n",
            "                   all         32        225      0.927      0.963      0.946      0.669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/35      1.07G     0.9074     0.5225      0.886         77        256: 100% 329/329 [00:41<00:00,  7.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.65it/s]\n",
            "                   all         32        225      0.919       0.96      0.931      0.656\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/35      1.07G      0.893     0.5087     0.8819         61        256: 100% 329/329 [00:41<00:00,  7.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.68it/s]\n",
            "                   all         32        225      0.923      0.963      0.925      0.664\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/35      1.07G      0.878     0.4983     0.8793         79        256: 100% 329/329 [00:41<00:00,  7.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.01it/s]\n",
            "                   all         32        225      0.895      0.964      0.922      0.647\n",
            "\n",
            "35 epochs completed in 0.526 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.128 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.99it/s]\n",
            "                   all         32        225      0.889      0.973      0.941      0.694\n",
            "Speed: 0.0ms preprocess, 0.6ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect \\\n",
        "mode=train \\\n",
        "model=yolov8s.pt \\\n",
        "data={dataset.location}/data.yaml \\\n",
        "epochs=35 \\\n",
        "imgsz=240,80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsBpUc_j43C7",
        "outputId": "fd696d55-c95a-49fc-fef9-7130fa5b1763",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.128 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/test3--2/valid/labels.cache... 32 images, 1 backgrounds, 0 corrupt: 100% 32/32 [00:00<?, ?it/s]\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 179, len(boxes) = 225. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:02<00:00,  1.02s/it]\n",
            "                   all         32        225      0.889      0.973      0.942      0.695\n",
            "Speed: 0.3ms preprocess, 3.8ms inference, 0.0ms loss, 11.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect \\\n",
        "mode=val \\\n",
        "model=./runs/detect/train/weights/best.pt \\\n",
        "data={dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KES_FSEW43C8",
        "outputId": "aa63d948-4cbd-47ee-d6ca-138f864417d5",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.128 🚀 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 11125971 parameters, 0 gradients\n",
            "\n",
            "image 1/34 /content/test3--2/test/images/DataTrain11_png_jpg.rf.f7173fc34b0e4cbc8855ae68964e837e.jpg: 96x256 7 texts, 63.0ms\n",
            "image 2/34 /content/test3--2/test/images/DataTrain122_png_jpg.rf.ef087e1e3f9d551837ae8bab9299363e.jpg: 96x256 7 texts, 9.0ms\n",
            "image 3/34 /content/test3--2/test/images/DataTrain123_png_jpg.rf.65e041988321114da3f6a6eaf272e379.jpg: 96x256 12 texts, 12.0ms\n",
            "image 4/34 /content/test3--2/test/images/DataTrain137_png_jpg.rf.5952f981a356c1ce5fdce6cd1e3d2e94.jpg: 96x256 8 texts, 8.6ms\n",
            "image 5/34 /content/test3--2/test/images/DataTrain144_png_jpg.rf.f9ca5bda99f3d04bdb2b38c92d32a28f.jpg: 96x256 8 texts, 8.7ms\n",
            "image 6/34 /content/test3--2/test/images/DataTrain164_png_jpg.rf.c30b4f66b872b5dfd8cac3d43238cdab.jpg: 96x256 8 texts, 8.7ms\n",
            "image 7/34 /content/test3--2/test/images/DataTrain208_png_jpg.rf.a76d560aade1ff05f77ed25a43ae6a02.jpg: 96x256 8 texts, 8.6ms\n",
            "image 8/34 /content/test3--2/test/images/DataTrain25_png_jpg.rf.3adefb257bcde301f8e399753f8277ac.jpg: 96x256 7 texts, 8.6ms\n",
            "image 9/34 /content/test3--2/test/images/DataTrain260_png_jpg.rf.ee585ed46da43d52dac9166987541204.jpg: 96x256 7 texts, 8.6ms\n",
            "image 10/34 /content/test3--2/test/images/DataTrain285_png_jpg.rf.f5ce5d2c0424ae4c4d2387cfaf4f214e.jpg: 96x256 8 texts, 8.8ms\n",
            "image 11/34 /content/test3--2/test/images/DataTrain287_png_jpg.rf.38abff6bf65206e93fed3f16e32fe8d3.jpg: 96x256 8 texts, 8.7ms\n",
            "image 12/34 /content/test3--2/test/images/DataTrain299_png_jpg.rf.8cc4d2439a6c79042c4a45308f8eb1eb.jpg: 96x256 7 texts, 8.8ms\n",
            "image 13/34 /content/test3--2/test/images/DataTrain302_png_jpg.rf.3ab4d752e15b83fd4dad0f470856d283.jpg: 96x256 10 texts, 9.3ms\n",
            "image 14/34 /content/test3--2/test/images/DataTrain306_png_jpg.rf.6759c306532840cadcc49da1a7058c68.jpg: 96x256 8 texts, 10.1ms\n",
            "image 15/34 /content/test3--2/test/images/DataTrain345_png_jpg.rf.97d764e94bf72d2d94f3339532e73814.jpg: 96x256 8 texts, 8.7ms\n",
            "image 16/34 /content/test3--2/test/images/DataTrain368_png_jpg.rf.c33c4f948b130c61c4b148efcf0205df.jpg: 96x256 8 texts, 8.7ms\n",
            "image 17/34 /content/test3--2/test/images/DataTrain374_png_jpg.rf.d5d164d09e2532c3197361b214a372c9.jpg: 96x256 8 texts, 8.8ms\n",
            "image 18/34 /content/test3--2/test/images/DataTrain375_png_jpg.rf.81494dfcbb18eb5275e89937d2826a9e.jpg: 96x256 9 texts, 7.4ms\n",
            "image 19/34 /content/test3--2/test/images/DataTrain401_png_jpg.rf.fa6c562c42b2c6bc0bef0a4bc14341c9.jpg: 96x256 9 texts, 7.4ms\n",
            "image 20/34 /content/test3--2/test/images/DataTrain404_png_jpg.rf.53b9a348f31b061ae689fdc0b9e0fa27.jpg: 96x256 8 texts, 6.4ms\n",
            "image 21/34 /content/test3--2/test/images/DataTrain447_png_jpg.rf.da36de510d661385eada8af72e1920ae.jpg: 96x256 10 texts, 8.1ms\n",
            "image 22/34 /content/test3--2/test/images/DataTrain476_png_jpg.rf.07d0d95b78547afdfb401d1cbe2cdc78.jpg: 96x256 8 texts, 6.1ms\n",
            "image 23/34 /content/test3--2/test/images/DataTrain548_png_jpg.rf.3af2a51a8b566c025053991b7961325d.jpg: 96x256 8 texts, 6.1ms\n",
            "image 24/34 /content/test3--2/test/images/DataTrain56_png_jpg.rf.a69044ce89b42634a0ef1625ebc9c69f.jpg: 96x256 8 texts, 6.5ms\n",
            "image 25/34 /content/test3--2/test/images/DataTrain583_png_jpg.rf.3a3b555be8bc1e0c21e863f9bf4a714e.jpg: 96x256 7 texts, 6.2ms\n",
            "image 26/34 /content/test3--2/test/images/DataTrain596_png_jpg.rf.b0aff76a019f9a20fdc961d1e332347c.jpg: 96x256 9 texts, 6.2ms\n",
            "image 27/34 /content/test3--2/test/images/DataTrain615_png_jpg.rf.f7d9fa547a71fd2c873bfffdeb219c8f.jpg: 96x256 7 texts, 6.3ms\n",
            "image 28/34 /content/test3--2/test/images/DataTrain646_png_jpg.rf.de429f8336b77fe08cc52d7a30edac02.jpg: 96x256 8 texts, 6.3ms\n",
            "image 29/34 /content/test3--2/test/images/DataTrain667_png_jpg.rf.109595b48d013934afa517a2b9bedcdb.jpg: 96x256 13 texts, 6.2ms\n",
            "image 30/34 /content/test3--2/test/images/DataTrain704_png_jpg.rf.c9fc5a5eb1e55607375dcfcbe8dbfade.jpg: 96x256 8 texts, 6.3ms\n",
            "image 31/34 /content/test3--2/test/images/DataTrain728_png_jpg.rf.849116e45f4d7f598dde0f41e87b424c.jpg: 96x256 8 texts, 6.1ms\n",
            "image 32/34 /content/test3--2/test/images/DataTrain729_png_jpg.rf.39266e4ec2ead42d4e5e04f129e588d8.jpg: 96x256 8 texts, 6.2ms\n",
            "image 33/34 /content/test3--2/test/images/DataTrain77_png_jpg.rf.ff7b756df415147abe95aa0d10a03b24.jpg: 96x256 8 texts, 6.2ms\n",
            "image 34/34 /content/test3--2/test/images/DataTrain82_png_jpg.rf.89c61fbbd0d6c286a8c1e1c962df5bfd.jpg: 96x256 8 texts, 6.1ms\n",
            "Speed: 0.4ms preprocess, 9.4ms inference, 3.6ms postprocess per image at shape (1, 3, 96, 256)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect \\\n",
        "mode=predict \\\n",
        "model=./runs/detect/train/weights/best.pt \\\n",
        "conf=0.25 \\\n",
        "source={dataset.location}/test/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au94D01LgNPa",
        "outputId": "8955058c-296d-4c33-fd2e-441c193d99f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/segmentation_weights.zip\n"
          ]
        }
      ],
      "source": [
        "# save weight\n",
        "\n",
        "import shutil\n",
        "import os.path\n",
        "\n",
        "path = '/content/runs/detect/train/weights/'\n",
        "output_dir = \"segmentation_weights\"\n",
        "\n",
        "# Creating the ZIP file\n",
        "archived = shutil.make_archive(output_dir, 'zip', path)\n",
        "\n",
        "if os.path.exists(output_dir+\".zip\"):\n",
        "   print(archived)\n",
        "else:\n",
        "   print(\"ZIP file not created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDBQn8aZ8n4e",
        "outputId": "51ba6edc-69dd-46da-8b87-2ef152b2c5bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/runs/detect/train/weights/ (stored 0%)\n",
            "  adding: content/runs/detect/train/weights/last.pt (deflated 8%)\n",
            "  adding: content/runs/detect/train/weights/best.pt (deflated 8%)\n"
          ]
        }
      ],
      "source": [
        "# # save weight\n",
        "# !zip -r weights.zip /content/runs/detect/train/weights"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
